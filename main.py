"""
Main Script - Income Classifier with Spark ML
==============================================

This is the main entry point to run the complete income
classification analysis.

Usage:
    python main.py
"""

import sys
import os

# Add directories to path
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'config'))

from spark_config import create_spark_session, stop_spark_session
from income_classifier import IncomeClassifier
from utils import analyze_data_distribution, evaluate_model_performance, save_results_to_file, create_prediction_summary

def main():
    """
    Main function that runs the complete analysis
    """
    print("=" * 80)
    print("ğŸ¦ CLASIFICADOR DE INGRESOS CON SPARK ML - ANÃLISIS COMPLETO")
    print("=" * 80)
    
    data_path = "data/adult_income_sample.csv"
    spark = None
    
    try:
        print("\nğŸš€ Inicializando Spark...")
        spark = create_spark_session("IncomeClassifierComplete")
        print("âœ… Spark inicializado correctamente")

        if not os.path.exists(data_path):
            print(f"âŒ Error: Data file not found at {data_path}")
            return 1

        classifier = IncomeClassifier(data_path)
        classifier.spark = spark 
        
        print("\nğŸ“Š Cargando y analizando datos...")
        classifier.load_data()
        
        print("\nğŸ” Realizando anÃ¡lisis exploratorio...")
        pandas_df = analyze_data_distribution(classifier.df, spark)
        
        print("\nğŸ”§ Preprocesando datos...")
        preprocessing_stages = classifier.preprocess_data()
        
        print("\nğŸ¤– Creando y entrenando modelo...")
        classifier.create_model(preprocessing_stages)
        predictions = classifier.train_model()
        
        print("\nğŸ“ˆ Evaluando rendimiento del modelo...")
        results = evaluate_model_performance(predictions)
        
        if results:
            print("\nğŸ’¾ Guardando resultados...")
            save_results_to_file(results)
        
        create_prediction_summary(predictions, spark)
        
        print("\nğŸ†• Creando datos nuevos para predicciÃ³n...")
        new_df = classifier.create_new_data()
        new_predictions = classifier.predict_new_data(new_df)
        
        print("\nğŸ‰ ANÃLISIS COMPLETO FINALIZADO EXITOSAMENTE!")
        print("\nğŸ“Š Resumen del anÃ¡lisis:")
        print(f"   â€¢ Dataset: {classifier.df.count()} registros")
        if results:
            print(f"   â€¢ PrecisiÃ³n del modelo: {results['precision']:.3f}")
            print(f"   â€¢ Sensibilidad: {results['recall']:.3f}")
            print(f"   â€¢ F1-Score: {results['f1_score']:.3f}")
            print(f"   â€¢ Exactitud: {results['accuracy']:.3f}")
        
    except Exception as e:
        print(f"\nâŒ Error durante el anÃ¡lisis: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1
        
    finally:
        if spark:
            stop_spark_session(spark)
            print("\nğŸ›‘ SesiÃ³n de Spark detenida")
    
    return 0

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
